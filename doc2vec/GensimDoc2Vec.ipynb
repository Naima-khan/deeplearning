{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docLabels = []\n",
    "docLabels = [f for f in listdir(\"data\") if \n",
    " f.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.txt', '10.txt', '2.txt', '3.txt', '4.txt', '5.txt', '6.txt', '7.txt', '8.txt', '9.txt']\n"
     ]
    }
   ],
   "source": [
    "print (docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for doc in docLabels:\n",
    "    data.append(open(\"data/\" + doc).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cricket is\n"
     ]
    }
   ],
   "source": [
    "print (data[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "#This function does all cleaning of data using two objects above\n",
    "def nlp_clean(data):\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_str = d.lower()\n",
    "        dlist = tokenizer.tokenize(new_str)\n",
    "        dlist = list(set(dlist).difference(stopword_set))\n",
    "        new_data.append(dlist)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "              yield gensim.models.doc2vec.LabeledSentence(doc,[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = nlp_clean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['result', 'two', 'innings', 'centre', 'gained', 'scores', 'depending', 'wicket', 'played', 'match', 'team', 'opponents', 'ball', 'next', 'except', 'long', 'phase', 'yard', 'including', 'teams', 'apiece', 'runs', 'roles', 'play', 'bats', 'field', 'rectangular', 'eleven', 'type', 'called', 'target', 'whilst', 'set', 'winning', 'matches', 'wooden', 'stumps', 'attempting', 'end', 'swap', 'players', 'bails', 'extras', 'first', 'ends', 'one', 'cricket', '22', 'topped', 'possible', 'three', 'many', 'draw', 'game', 'pitch', 'score', 'bat']\n"
     ]
    }
   ],
   "source": [
    "print (data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = LabeledLineSentence(data, docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=300, min_count=0, alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(it)\n",
    "#training of model\n",
    "for epoch in range(100):\n",
    "    #print ('iteration '+str(epoch+1))\n",
    "    model.train(it, total_examples=model.corpus_count,epochs=model.iter)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha\n",
    "#saving the created model\n",
    "#model.save(‘doc2vec.model’)\n",
    "#print (“model saved”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##loading the model\n",
    "#d2v_model = gensim.models.doc2vec.Doc2Vec.load(‘doc2vec.model’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = model\n",
    "docvec = d2v_model.docvecs[0]\n",
    "#print (docvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "docvec = d2v_model.docvecs['1.txt'] #if string tag used in training\n",
    "#print (docvec)  #same but refeences with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3.txt', 0.9999394416809082), ('10.txt', 0.9998970031738281), ('2.txt', 0.9998953938484192), ('7.txt', 0.9997853636741638), ('6.txt', 0.9997463226318359), ('4.txt', 0.9997228980064392), ('8.txt', 0.9996271729469299), ('5.txt', 0.9995402097702026), ('9.txt', 0.9993734359741211)]\n"
     ]
    }
   ],
   "source": [
    "sims = d2v_model.docvecs.most_similar('1.txt')\n",
    "print (sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get vector of document that are not present in corpus \n",
    "docvec = d2v_model.infer_vector([\"google\",\"is\",\"a\",\"search\", \"engine\"])\n",
    "#print (docvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.txt', -0.9998027086257935),\n",
       " ('9.txt', -0.9998462200164795),\n",
       " ('5.txt', -0.9999169111251831),\n",
       " ('8.txt', -0.9999468922615051),\n",
       " ('3.txt', -0.9999501705169678),\n",
       " ('10.txt', -0.9999712109565735),\n",
       " ('4.txt', -0.9999712109565735),\n",
       " ('2.txt', -0.9999716281890869),\n",
       " ('6.txt', -0.9999752640724182),\n",
       " ('7.txt', -0.9999803304672241)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs.most_similar([docvec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
