{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]\n",
      "[ 0.013441    0.23682    -0.16899     0.40950999  0.63812     0.47709\n",
      " -0.42851999 -0.55641001 -0.36399999 -0.23938     0.13000999 -0.063734\n",
      " -0.39574999 -0.48162001  0.23291001  0.090201   -0.13324     0.078639\n",
      " -0.41633999 -0.15428001  0.10068     0.48890999  0.31226    -0.1252\n",
      " -0.037512   -1.51789999  0.12612    -0.02442    -0.042961   -0.28351\n",
      "  3.54159999 -0.11956    -0.014533   -0.1499      0.21864    -0.33412001\n",
      " -0.13872001  0.31806001  0.70358002  0.44858    -0.080262    0.63002998\n",
      "  0.32111001 -0.46765     0.22786     0.36034    -0.37818    -0.56656998\n",
      "  0.044691    0.30392   ]\n",
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "print (wordsList[0:10])\n",
    "print (wordVectors[1])\n",
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 200 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3106\n",
      "[-0.90742999  0.30886999  1.06040001  0.088596    0.30813     0.38332\n",
      " -0.43077999 -0.096476    0.51664001  0.186       0.28332001 -0.76336002\n",
      " -0.63599998  0.52166998  0.88101     0.1594      0.30474001 -0.31674001\n",
      " -1.57270002 -1.12030005  0.43566    -0.53811997 -0.37351999 -0.47691\n",
      "  0.92426002 -0.99818999 -0.30322    -0.065498    0.49301001 -0.1758\n",
      "  2.10019994  0.70359999  0.037695    0.78171998 -0.13428    -0.85176998\n",
      " -0.060642    0.47088     0.014336   -0.65079999 -0.59218001 -0.34836999\n",
      "  0.34900999  0.012822    0.19881    -1.148       1.25660002 -0.35398999\n",
      "  0.15462001 -0.007928  ]\n"
     ]
    }
   ],
   "source": [
    "baseballIndex = wordsList.index('jump')\n",
    "print (baseballIndex)\n",
    "print (wordVectors[baseballIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "[    41    804 201534   1005     15   7446      5  13767      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "#firstSentence[8] and firstSentence[9] are going to be 0\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read stumple upon ever green content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping because of error\n",
      "7395\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "i=0\n",
    "content = []\n",
    "with open(\"stumbleupon/train.tsv\") as f:\n",
    "    tsvreader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for row in tsvreader:\n",
    "        i = i  + 1\n",
    "        if i < 2:\n",
    "            continue\n",
    "        #print (row[2])\n",
    "        news = json.loads(row[2])\n",
    "        #print (news)\n",
    "        try:\n",
    "            title = news[\"title\"]\n",
    "            if title == None:\n",
    "                title = \"\"\n",
    "            body = news[\"body\"]\n",
    "            if body == None:\n",
    "                body = \"\"\n",
    "        except KeyError:\n",
    "            print (\"skipping because of error\")\n",
    "        label = int(row[26])\n",
    "        content.append((title,body,label))\n",
    "        #print (title, label)\n",
    "\n",
    "print (len(content))\n",
    "#print (content[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "wordIndex = {}\n",
    "for word in wordsList:\n",
    "    wordIndex[word] = i\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileCounter = 0\n",
    "ids = np.zeros((len(content), maxSeqLength), dtype='int32')\n",
    "labels = np.zeros((len(content), 2), dtype='int32')\n",
    "for (title,body,label) in content:\n",
    "#     if fileCounter > 100:\n",
    "#         break\n",
    "    \n",
    "    fullText = title + \" \" + body\n",
    "    fullText = cleanSentences(fullText)\n",
    "    #print (fullText)\n",
    "    split = fullText.split()\n",
    "    indexCounter = 0\n",
    "    for word in split:\n",
    "        #print (word)\n",
    "        try:\n",
    "            #print (word,indexCounter,  wordsList.index(word))\n",
    "            #ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "            ids[fileCounter][indexCounter] = wordIndex[word]\n",
    "        except KeyError:\n",
    "            ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        #print (indexCounter)\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "    if label == 1:\n",
    "        labels[fileCounter,:] = [1,0]\n",
    "    else:\n",
    "        labels[fileCounter,:] = [0,1]\n",
    "\n",
    "    fileCounter = fileCounter + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    55   4719   8628 ...,   6988      5      7]\n",
      " [    96  10267      5 ...,    101   1547     12]\n",
      " [  5578   1163  10817 ...,   3634    314    409]\n",
      " ..., \n",
      " [    66      3     37 ...,     39    390    841]\n",
      " [ 25663   3305    719 ...,  31929  24309 201534]\n",
      " [  8628  19829   5015 ...,      0      0      0]] [[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "7395\n"
     ]
    }
   ],
   "source": [
    "print (ids[500:510,:], labels[500:510,:])\n",
    "print (len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size 2395\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = 5000\n",
    "test_size = len(labels) - train_size\n",
    "print (\"test_size\",test_size)\n",
    "train_ids = ids[0:train_size,:]\n",
    "train_labels = labels[0:train_size,:]\n",
    "test_ids = ids[train_size+1:,:]\n",
    "test_labels = labels[train_size+1:,:]\n",
    "#print (train_labels)\n",
    "#print (test_labels)\n",
    "\n",
    "print(len(train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getBatch(train, labels):\n",
    "    batch_labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    size = len(train)\n",
    "    #print (size)\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,size)\n",
    "        labels_list = labels[num-1:num][0,:].tolist()\n",
    "        batch_labels.append(labels_list)\n",
    "        arr[i] = train[num-1:num]\n",
    "    return arr, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = getBatch(train_ids,train_labels)\n",
    "#print(ret[0],ret[1])\n",
    "ret = getBatch(test_ids,test_labels)\n",
    "#print(ret[0],ret[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to models/pretrained_lstm.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iterations = 10010\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "   #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getBatch(train_ids,train_labels)\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "   #Write summary to Tensorboard\n",
    "    if (i % 50 == 0):\n",
    "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "   #Save the network every 10,000 training iterations\n",
    "    if (i % 10000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-40000\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key Variable_1/Adam_1 not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2_3', defined at:\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-135-c8baba70c58c>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key Variable_1/Adam_1 not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_1/Adam_1 not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-c8baba70c58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_1/Adam_1 not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2_3', defined at:\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-135-c8baba70c58c>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/nahmad/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key Variable_1/Adam_1 not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 100.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 66.6666686535\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 70.8333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 95.8333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Average Accuracy  74.8749999404\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "accur = []\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getBatch(test_ids,test_labels)\n",
    "    a = (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100\n",
    "    accur.append(a)\n",
    "    print(\"Accuracy for this batch:\", a)\n",
    "\n",
    "sum = 0\n",
    "for s in accur:\n",
    "    sum += s\n",
    "    \n",
    "print (\"Average Accuracy \", sum/len(accur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
